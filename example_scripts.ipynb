{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70f52a3e-6bb7-4710-814b-641ae2e27fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from glob import glob\n",
    "import bisect\n",
    "from bisect import bisect_left\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169be304-94eb-4cf8-8be4-ff483528657e",
   "metadata": {},
   "source": [
    "### Example code:\n",
    "1. Convert local time string to timestamp\n",
    "2. Match personal-daybreak days in study to timestamp\n",
    "3. Match nearest-time sensor log to timestamp\n",
    "4. X-min window of sensor data aggregates before/after timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258d230-cc8f-4f06-94dd-eab16349eac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b505b26-56a0-4f1a-b9dd-3d5c77f131cb",
   "metadata": {},
   "source": [
    "### 1. Convert local time string to timestamp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ca7a04-35e9-4ed0-af39-9d786fd64e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: dataframe, column name of local time, column name of timestamp\n",
    "Output: dataframe\n",
    "'''\n",
    "\n",
    "time_offset_dict = {\n",
    "    \"CDT\": \"UTC-05\",\n",
    "    \"CST\": \"UTC-06\",\n",
    "    \"MDT\": \"UTC-06\",\n",
    "    \"MST\": \"UTC-07\",\n",
    "    \"PDT\": \"UTC-07\",\n",
    "    \"PST\": \"UTC-08\",\n",
    "    \"EDT\": \"UTC-04\",\n",
    "    \"EST\": \"UTC-05\",\n",
    "    \"AKDT\": \"UTC-08\",\n",
    "    \"AKST\": \"UTC-09\",\n",
    "    \"HDT\": \"UTC-09\",\n",
    "    \"HST\": \"UTC-10\"\n",
    "}\n",
    "\n",
    "def get_time_offset(time_zone_abbr):\n",
    "    time_delta = datetime.timedelta(hours=0)\n",
    "    sign = 0\n",
    "\n",
    "    if time_zone_abbr in time_offset_dict:\n",
    "        time_offset = time_offset_dict[time_zone_abbr]\n",
    "        time_delta, sign = parse_time_offset(time_offset)\n",
    "\n",
    "    return time_delta, sign\n",
    "\n",
    "def convert_local_time_to_timestamp(local_time):\n",
    "    if len(local_time.split(\" \")) < 3:\n",
    "        timestamp_str = \"unknown time zone\"\n",
    "    else:\n",
    "        time_zone = local_time.split(\" \")[2]\n",
    "        time_delta, sign = get_time_offset(time_zone)\n",
    "        if time_zone == \"unknownTZ\" or sign == 0:\n",
    "            timestamp_str = \"unknown time zone\"\n",
    "        else:\n",
    "            local_time = local_time.split(\" \")[0] + \" \" + local_time.split(\" \")[1]\n",
    "            if \".\" in local_time:\n",
    "                datetime_time = datetime.datetime.strptime(local_time, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "            else:\n",
    "                datetime_time = datetime.datetime.strptime(local_time, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            datetime_time_tz = datetime_time - sign * time_delta\n",
    "            timestamp_str = datetime_time_tz.replace(tzinfo=datetime.timezone.utc).timestamp()  # float\n",
    "\n",
    "    return timestamp_str\n",
    "\n",
    "def parse_time_offset(time_offset):\n",
    "    sign_str = time_offset.strip('UTC')[0]\n",
    "    if sign_str == \"-\":\n",
    "        sign = -1\n",
    "    elif sign_str == \"+\":\n",
    "        sign = 1\n",
    "    else:\n",
    "        sigh = 0\n",
    "\n",
    "    time_offset_int = int(time_offset.strip('UTC')[1:])\n",
    "    time_delta = datetime.timedelta(hours=time_offset_int)\n",
    "\n",
    "    return time_delta, sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6274189b-0e50-4457-adf1-a3ee94395e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1622804400.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Example\n",
    "'''\n",
    "\n",
    "local_time = \"2021-06-04 07:00:00 EDT\"\n",
    "convert_local_time_to_timestamp(local_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0c779-dc0c-4456-a6cf-b750ead07cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed236e40-f8fb-4dbb-9653-e5e2569c1f60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d488bd-a231-47b7-bd29-765b8ff7da92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "458f9803-db58-49a0-92cd-d80ddd468dd7",
   "metadata": {},
   "source": [
    "### 2. Match personal-daybreak days in study to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f47c6fd-c251-46f3-90da-581d99e2cbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.jix/.conda/envs/time/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/li.jix/.conda/envs/time/lib/python3.7/site-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Input: personal daybreak daily report, participant_id_text, local time w/o timezone\n",
    "Output: personal-daybreak days in study\n",
    "'''\n",
    "\n",
    "# Read personal daybreak file\n",
    "personal_daily_report_file_path = \"/home/li.jix/repo/TIME/day_definition/adaptive_daily_report.csv\"\n",
    "df_personal = pd.read_csv(personal_daily_report_file_path)\n",
    "df_personal_lite = df_personal[[\"participant_id_text\",\"participant_id_numeric\",\"days_in_study\",\"last_breaktime\",\"current_breaktime\"]]\n",
    "\n",
    "\n",
    "# Without timezone info, we don't know the unix time equivalent, but it's ok to assume the converted datetime are in the same time zone and compare among them\n",
    "def convert_local_time_to_datetime(local_time):\n",
    "    if pd.isna(local_time):\n",
    "        return local_time\n",
    "    \n",
    "    split = local_time.split(\" \")\n",
    "    if len(split) > 2:\n",
    "        local_time = split[0] + \" \" + split[1]\n",
    "    \n",
    "    if \"/\" in local_time:\n",
    "        local_time_dt = datetime.datetime.strptime(local_time, '%m/%d/%Y %H:%M:%S')\n",
    "    elif \"-\" in local_time:\n",
    "        local_time_dt = datetime.datetime.strptime(local_time, '%Y-%m-%d %H:%M:%S')\n",
    "    return local_time_dt\n",
    "        \n",
    "\n",
    "df_personal_lite[\"last_breaktime_dt\"] = [convert_local_time_to_datetime(x) for x in df_personal_lite[\"last_breaktime\"]]\n",
    "df_personal_lite[\"current_breaktime_dt\"] = [convert_local_time_to_datetime(x) for x in df_personal_lite[\"current_breaktime\"]]\n",
    "\n",
    "\n",
    "\n",
    "def take_closest(mySeries, myNumber):\n",
    "\n",
    "    myList = list(mySeries)\n",
    "    pos = bisect_left(myList, myNumber)-1\n",
    "    if pos < 0:\n",
    "        return np.nan\n",
    "    elif pos == len(myList)-1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return mySeries.index[pos]\n",
    "\n",
    "def get_personal_daybreak_days_in_study(df_personal_lite, participant_id_text, time_to_check):\n",
    "    df_personal_lite_pid = df_personal_lite[df_personal_lite.participant_id_text == participant_id_text]\n",
    "    last_breaktime_dt_series = df_personal_lite_pid.last_breaktime_dt\n",
    "    idx_before = take_closest(last_breaktime_dt_series, time_to_check)\n",
    "    if pd.isna(idx_before):\n",
    "        days_in_study = np.nan\n",
    "    else:\n",
    "        days_in_study = df_personal_lite_pid.loc[idx_before,\"days_in_study\"]\n",
    "    return days_in_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0f2d16-034b-4f8f-ac2e-a4c1508c9e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Example\n",
    "'''\n",
    "\n",
    "local_time = \"2021-06-04 07:00:00\"\n",
    "participant_id_text = \"afflictedrevenueepilepsy\"\n",
    "local_time_dt = convert_local_time_to_datetime(local_time)\n",
    "days_in_study_personal_break = get_personal_daybreak_days_in_study(df_personal_lite, participant_id_text, local_time_dt)\n",
    "print(days_in_study_personal_break)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398eedc0-5050-4b10-9577-cfffc9049af5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589c7fb-00ab-42e7-9199-c7abe5ffb0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8148d10-579e-4f0a-b9aa-71eab9f2e716",
   "metadata": {},
   "source": [
    "### 3. Match nearest-time sensor log to timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "595205fe-b52a-4812-add5-ec6113066130",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input: target_file_pattern, pid, datetime_match_to_list\n",
    "Output: matched data column, matched time column\n",
    "'''\n",
    "def extract_participant_id(intermediate_participant_path):\n",
    "\n",
    "    participant_id = intermediate_participant_path.split(os.sep)[-1]\n",
    "\n",
    "    if not participant_id.endswith(\"@timestudy_com\"):\n",
    "        raise Exception(\"Wrong format for input folder path. Needs to be '..\\\\username@timestudy_com'\")\n",
    "\n",
    "    return participant_id\n",
    "\n",
    "\n",
    "def get_min_diff(prompt_datetime, matched_datetime):\n",
    "    min_diff = abs((prompt_datetime - matched_datetime).total_seconds() / 60.0)\n",
    "    return min_diff\n",
    "\n",
    "def validate_dates_before_after(intermediate_participant_path, date_in_study):\n",
    "    validated_date_list = []\n",
    "\n",
    "    # target date\n",
    "    date_folder_path = intermediate_participant_path + os.sep + date_in_study\n",
    "    target_date_log_paths = sorted(glob(os.path.join(date_folder_path, target_file_pattern)))  # file name\n",
    "    if len(target_date_log_paths) == 0:\n",
    "        print(\"No battery daily file on {}\".format(date_in_study))\n",
    "    else:\n",
    "\n",
    "        # 1 day before target date\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        one_date_before_datetime = datetime.datetime.strptime(date_in_study, date_format).date() - timedelta(days=1)\n",
    "        one_date_before = one_date_before_datetime.strftime(date_format)\n",
    "        date_folder_path = intermediate_participant_path + os.sep + one_date_before\n",
    "        one_day_before_log_paths = sorted(glob(os.path.join(date_folder_path, target_file_pattern)))  # file name\n",
    "        if len(one_day_before_log_paths) != 0:\n",
    "            validated_date_list.append(one_date_before)\n",
    "\n",
    "        # target date\n",
    "        validated_date_list.append(date_in_study)\n",
    "\n",
    "        # 1 day after target date\n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        one_date_after_datetime = datetime.datetime.strptime(date_in_study, date_format).date() + timedelta(days=1)\n",
    "        one_date_after = one_date_after_datetime.strftime(date_format)\n",
    "        date_folder_path = intermediate_participant_path + os.sep + one_date_after\n",
    "        one_day_after_log_paths = sorted(glob(os.path.join(date_folder_path, target_file_pattern)))  # file name\n",
    "        if len(one_day_after_log_paths) != 0:\n",
    "            validated_date_list.append(one_date_after)\n",
    "\n",
    "    return validated_date_list\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    dropped_rows = []\n",
    "    for idx in df.index:\n",
    "        local_time_str = df[\"LOG_TIME\"][idx]\n",
    "        if (local_time_str == \"-1\") or len(local_time_str.split(' ')) > 3 or len(local_time_str.split('-')[0]) > 4 or len(local_time_str.split(' ')) < 2:\n",
    "            dropped_rows.append(idx)\n",
    "    df = df.drop(dropped_rows)\n",
    "\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    return df\n",
    "\n",
    "def combine_intermediate_file(intermediate_participant_path):\n",
    "    df_logs_combined = pd.DataFrame()\n",
    "    participant_id = extract_participant_id(intermediate_participant_path)\n",
    "    \n",
    "    for file in glob(os.path.join(intermediate_participant_path,target_file_pattern)):\n",
    "        df_logs_combined = pd.read_csv(file)\n",
    "        \n",
    "\n",
    "        converter = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "        df_logs_combined = df_logs_combined.dropna(subset=['LOG_TIME'])\n",
    "        df_logs_combined = clean_dataframe(df_logs_combined)\n",
    "\n",
    "        try:\n",
    "            df_logs_combined[\"LOG_TIME\"] = [x.split(\" \")[0] + \" \" + x.split(\" \")[1] for x in\n",
    "                                              list(df_logs_combined[\"LOG_TIME\"])]\n",
    "\n",
    "            df_logs_combined['LOG_TIMESTAMP'] = pd.Series(map(converter, df_logs_combined[\"LOG_TIME\"]))\n",
    "            # print(df_logs_combined['Local_Timestamp'])\n",
    "            df_logs_combined['Date'] = df_logs_combined['LOG_TIMESTAMP'].dt.date\n",
    "        except IndexError:\n",
    "            raise Exception(\n",
    "                \"IndexError: list index out of range (battery_level) : \" + intermediate_participant_path + os.sep + date_in_study + str(\n",
    "                    list(df_logs_combined[\"LOG_TIME\"])))\n",
    "        except Exception:\n",
    "            raise Exception(\"Exception (battery_level) : \" + intermediate_participant_path + os.sep + date_in_study)\n",
    "\n",
    "    return df_logs_combined\n",
    "\n",
    "\n",
    "def find_closest_time(prompt_time, subset_time_list):\n",
    "    i = bisect.bisect_left(subset_time_list, prompt_time)\n",
    "    closet_time = min(subset_time_list[max(0, i - 1): i + 2], key=lambda t: abs(prompt_time - t))\n",
    "    return closet_time\n",
    "\n",
    "\n",
    "def match_feature(datetime_match_to_list, df_logs_combined):\n",
    "    print(\"     --- start matching\")\n",
    "    matched_battery_level_list = []\n",
    "    matched_charging_status_list = []\n",
    "    matched_time_list = []\n",
    "\n",
    "    for idx in range(len(datetime_match_to_list)):\n",
    "        prompt_time = datetime_match_to_list[idx]\n",
    "        # prompt_date = prompt_time.date()\n",
    "\n",
    "        if df_logs_combined.shape[0] == 0:\n",
    "            battery_level = \"NF\"\n",
    "            charging_status = \"NF\"\n",
    "            closest_time = \"NF\"\n",
    "        else:\n",
    "            subset_time_list = list(df_logs_combined[\"LOG_TIMESTAMP\"])\n",
    "\n",
    "            closest_time = find_closest_time(prompt_time, subset_time_list)\n",
    "\n",
    "            # check if matched time is 5 minutes away from prompt time\n",
    "            if get_min_diff(prompt_time, closest_time) < 5:\n",
    "                battery_level = list(df_logs_combined[df_logs_combined['LOG_TIMESTAMP'] == closest_time][\n",
    "                                         \"Percentage\"])[0]\n",
    "                charging_status = list(df_logs_combined[df_logs_combined['LOG_TIMESTAMP'] == closest_time][\n",
    "                                           \"isCharging\"])[0]\n",
    "            else:\n",
    "                battery_level = \"NF\"\n",
    "                charging_status = \"NF\"\n",
    "\n",
    "\n",
    "        matched_time_list.append(closest_time)\n",
    "        matched_battery_level_list.append(battery_level)\n",
    "        matched_charging_status_list.append(charging_status)\n",
    "\n",
    "    return matched_battery_level_list, matched_charging_status_list, matched_time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "983666e7-00f2-418e-b177-482dcf6cbbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.jix/.conda/envs/time/lib/python3.7/site-packages/ipykernel_launcher.py:14: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     --- start matching\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Example\n",
    "'''\n",
    "\n",
    "# Input\n",
    "target_file_pattern = 'phone_battery.csv' # sensor intermediate data file to match datetime with\n",
    "intermediate_data_path = \"/work/mhealthresearchgroup/TIME_STD/time_study_preprocess/intermediate_file/\"\n",
    "pid = \"arrivejanitoruniformly@timestudy_com\"\n",
    "intermediate_participant_path = os.path.join(intermediate_data_path, pid)\n",
    "date_in_study = \"2021-03-12\"\n",
    "datetime_match_to_list = [convert_local_time_to_datetime(\"2021-03-12 07:00:00\"), convert_local_time_to_datetime(\"2021-03-12 08:00:00\")] # the list of time you want sensor data match to\n",
    "\n",
    "# Read, parse and combine related intermediate file\n",
    "df_logs_combined = combine_intermediate_file(intermediate_participant_path)\n",
    "\n",
    "# Get the battery, charging status matched to the datetime list\n",
    "if df_logs_combined.shape[0] > 0:\n",
    "    # Match the combined parsed intermediate file with prompt feature data frame\n",
    "    battery_level_column, charging_status_column, match_time = match_feature(datetime_match_to_list, df_logs_combined)\n",
    "else:\n",
    "    battery_level_column = [\"NF\"] * len(datetime_match_to_list)\n",
    "    charging_status_column = [\"NF\"] * len(datetime_match_to_list)\n",
    "    match_time = [\"NF\"] * len(datetime_match_to_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "042f6911-7207-4a73-ada5-c5d3c027b81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 100]\n"
     ]
    }
   ],
   "source": [
    "print(battery_level_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0ef63c85-4a58-4ac7-bf03-e97d347978f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True]\n"
     ]
    }
   ],
   "source": [
    "print(charging_status_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ac4be589-dfa0-4627-8c46-0827456fdf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Timestamp('2021-03-12 07:00:18.291000'), Timestamp('2021-03-12 07:59:57.801000')]\n"
     ]
    }
   ],
   "source": [
    "print(match_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7c782e-6162-4d4b-a036-f7a56475d6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10637494-5595-4c7b-8068-9b0173615f8d",
   "metadata": {},
   "source": [
    "### 4. X-min window of sensor data aggregates before/after timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef5ece4-cddf-4a3f-bfd4-e18a09e95eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Input: target_file_pattern, pid, datetime_match_to_list\n",
    "Output: matched data column, matched time column\n",
    "'''\n",
    "\n",
    "def combine_intermediate_file(intermediate_participant_path):\n",
    "    df_logs_combined = pd.DataFrame()\n",
    "    participant_id = extract_participant_id(intermediate_participant_path)\n",
    "\n",
    "    for file in glob(os.path.join(intermediate_participant_path,target_file_pattern)):\n",
    "        df_logs_combined = pd.read_csv(file)\n",
    "    \n",
    "\n",
    "        converter = lambda x: datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\") if (\".\" in x) else datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        df_logs_combined = df_logs_combined.dropna(subset=['LOG_TIME'])\n",
    "        df_logs_combined.reset_index(inplace=True, drop=True)\n",
    "        df_logs_combined[\"LOG_TIME\"] = [x.split(\" \")[0] + \" \" + x.split(\" \")[1] for x in\n",
    "                                                 list(df_logs_combined[\"LOG_TIME\"])]\n",
    "\n",
    "        df_logs_combined['LOG_TIMESTAMP'] = pd.Series(map(converter, df_logs_combined[\"LOG_TIME\"]))\n",
    "\n",
    "\n",
    "    return df_logs_combined\n",
    "\n",
    "\n",
    "def find_closest_time(prompt_time, subset_time_list):\n",
    "    pos = bisect.bisect_left(subset_time_list, prompt_time)\n",
    "    # closet_time = min(subset_time_list[max(0, i - 1): i + 2], key=lambda t: -(prompt_time - t))\n",
    "\n",
    "    return pos\n",
    "\n",
    "\n",
    "def get_mims_summary(sec_before, prompt_time, closest_times, df_logs_combined):\n",
    "    mims_summary = 0\n",
    "    num_readings = 0\n",
    "    start_time = None\n",
    "    for matched_idx in closest_times:\n",
    "        closest_time = df_logs_combined.loc[matched_idx, \"LOG_TIMESTAMP\"]\n",
    "        if get_min_diff(prompt_time, closest_time) <= (sec_before // 60 + 1):\n",
    "            mims_min = df_logs_combined.loc[matched_idx, \"MIMS_UNIT\"]\n",
    "            if mims_min != -0.01:  # mims value -0.01 means cannot be computed\n",
    "                mims_summary += mims_min\n",
    "                num_readings += 1\n",
    "            start_time = closest_time\n",
    "        else:\n",
    "            if start_time is None:\n",
    "                mims_summary = \"OB\"\n",
    "            break\n",
    "    return mims_summary, num_readings, start_time\n",
    "\n",
    "\n",
    "def match_feature(datetime_match_to_list, df_logs_combined):\n",
    "    print(\"     --- start matching\")\n",
    "    # Aggregating 1-10 minutes before prompt time\n",
    "    sec_before_list = [60 * x for x in list(range(1, 11))] \n",
    "\n",
    "    mims_summary_list = []\n",
    "    start_time_list = []\n",
    "    readings_list = []\n",
    "\n",
    "    for idx in range(len(datetime_match_to_list)):\n",
    "        matched_mims_summary_list = []\n",
    "        matched_start_time_list = []\n",
    "        matched_readings_list = []\n",
    "\n",
    "        prompt_time = datetime_match_to_list[idx]\n",
    "        # prompt_date = prompt_time.date()\n",
    "\n",
    "        if df_logs_combined.shape[0] == 0:\n",
    "            matched_mims_summary_list = [np.nan] * len(sec_before_list)\n",
    "            matched_readings_list = [np.nan] * len(sec_before_list)\n",
    "            matched_start_time_list = [np.nan] * len(sec_before_list)\n",
    "        else:\n",
    "            subset_time_list = list(df_logs_combined[\"LOG_TIMESTAMP\"])\n",
    "            pos = find_closest_time(prompt_time, subset_time_list)\n",
    "\n",
    "            for sec_before in sec_before_list:\n",
    "                closest_times = []\n",
    "                for i in range(sec_before):\n",
    "                    closest_times.append(pos - 1 - i)\n",
    "                closest_times = [x for x in closest_times if x >= 0]\n",
    "                mims_summary, readings, start_time = get_mims_summary(sec_before, prompt_time, closest_times,\n",
    "                                                                      df_logs_combined)\n",
    "                matched_mims_summary_list.append(mims_summary)\n",
    "                matched_readings_list.append(readings)\n",
    "                matched_start_time_list.append(start_time)\n",
    "        mims_summary_list.append(matched_mims_summary_list)\n",
    "        readings_list.append(matched_readings_list)\n",
    "        start_time_list.append(matched_start_time_list)\n",
    "\n",
    "    mims_summary_df = pd.DataFrame(list(map(np.ravel, mims_summary_list)))\n",
    "    readings_df = pd.DataFrame(list(map(np.ravel, readings_list)))\n",
    "    start_time_df = pd.DataFrame(list(map(np.ravel, start_time_list)))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for sec_before in sec_before_list:\n",
    "        col = int(sec_before // 60 - 1)\n",
    "        df = pd.concat([df, mims_summary_df[col].rename(\"mims_summary_\" + str(sec_before // 60) + \"min\")], axis=1)\n",
    "        df = pd.concat([df, readings_df[col].rename(\"num_readings_\" + str(sec_before // 60) + \"min\")], axis=1)\n",
    "        df = pd.concat([df, start_time_df[col].rename(\"start_time_\" + str(sec_before // 60) + \"min\")], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55612c8-4bd9-413f-983e-e081ddc4e66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/li.jix/.conda/envs/time/lib/python3.7/site-packages/ipykernel_launcher.py:15: DtypeWarning: Columns (3) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     --- start matching\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Example\n",
    "'''\n",
    "\n",
    "\n",
    "# Input\n",
    "target_file_pattern = 'watch_accelerometer_mims.csv' # sensor intermediate data file to match datetime with\n",
    "intermediate_data_path = \"/work/mhealthresearchgroup/TIME_STD/time_study_preprocess/intermediate_file/\"\n",
    "pid = \"arrivejanitoruniformly@timestudy_com\"\n",
    "intermediate_participant_path = os.path.join(intermediate_data_path, pid)\n",
    "\n",
    "datetime_match_to_list = [convert_local_time_to_datetime(\"2021-03-12 07:00:00\"), convert_local_time_to_datetime(\"2021-03-12 08:00:00\")] # the list of time you want sensor data match to\n",
    "\n",
    "# Read, parse and combine related intermediate file\n",
    "df_logs_combined = combine_intermediate_file(intermediate_participant_path)\n",
    "\n",
    "# Match the combined parsed intermediate file with prompt feature data frame\n",
    "df = match_feature(datetime_match_to_list, df_logs_combined)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f2b41c-1161-4320-a915-a02d4b158203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mims_summary_1min</th>\n",
       "      <th>num_readings_1min</th>\n",
       "      <th>start_time_1min</th>\n",
       "      <th>mims_summary_2min</th>\n",
       "      <th>num_readings_2min</th>\n",
       "      <th>start_time_2min</th>\n",
       "      <th>mims_summary_3min</th>\n",
       "      <th>num_readings_3min</th>\n",
       "      <th>start_time_3min</th>\n",
       "      <th>mims_summary_4min</th>\n",
       "      <th>...</th>\n",
       "      <th>start_time_7min</th>\n",
       "      <th>mims_summary_8min</th>\n",
       "      <th>num_readings_8min</th>\n",
       "      <th>start_time_8min</th>\n",
       "      <th>mims_summary_9min</th>\n",
       "      <th>num_readings_9min</th>\n",
       "      <th>start_time_9min</th>\n",
       "      <th>mims_summary_10min</th>\n",
       "      <th>num_readings_10min</th>\n",
       "      <th>start_time_10min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2021-03-12 06:58:59.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>2021-03-12 06:57:59.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180</td>\n",
       "      <td>2021-03-12 06:56:59.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-03-12 06:52:59.002</td>\n",
       "      <td>11.814441</td>\n",
       "      <td>480</td>\n",
       "      <td>2021-03-12 06:51:59.002</td>\n",
       "      <td>11.814441</td>\n",
       "      <td>540</td>\n",
       "      <td>2021-03-12 06:50:59.002</td>\n",
       "      <td>11.814441</td>\n",
       "      <td>600</td>\n",
       "      <td>2021-03-12 06:49:59.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>2021-03-12 07:58:59.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120</td>\n",
       "      <td>2021-03-12 07:57:59.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180</td>\n",
       "      <td>2021-03-12 07:56:59.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-03-12 07:52:59.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>480</td>\n",
       "      <td>2021-03-12 07:51:59.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>540</td>\n",
       "      <td>2021-03-12 07:50:59.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>600</td>\n",
       "      <td>2021-03-12 07:49:59.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mims_summary_1min  num_readings_1min         start_time_1min  \\\n",
       "0                0.0                 60 2021-03-12 06:58:59.002   \n",
       "1                0.0                 60 2021-03-12 07:58:59.000   \n",
       "\n",
       "   mims_summary_2min  num_readings_2min         start_time_2min  \\\n",
       "0                0.0                120 2021-03-12 06:57:59.002   \n",
       "1                0.0                120 2021-03-12 07:57:59.000   \n",
       "\n",
       "   mims_summary_3min  num_readings_3min         start_time_3min  \\\n",
       "0                0.0                180 2021-03-12 06:56:59.002   \n",
       "1                0.0                180 2021-03-12 07:56:59.000   \n",
       "\n",
       "   mims_summary_4min  ...         start_time_7min mims_summary_8min  \\\n",
       "0                0.0  ... 2021-03-12 06:52:59.002         11.814441   \n",
       "1                0.0  ... 2021-03-12 07:52:59.000          0.000000   \n",
       "\n",
       "   num_readings_8min         start_time_8min mims_summary_9min  \\\n",
       "0                480 2021-03-12 06:51:59.002         11.814441   \n",
       "1                480 2021-03-12 07:51:59.000          0.000000   \n",
       "\n",
       "   num_readings_9min         start_time_9min mims_summary_10min  \\\n",
       "0                540 2021-03-12 06:50:59.002          11.814441   \n",
       "1                540 2021-03-12 07:50:59.000           0.000000   \n",
       "\n",
       "   num_readings_10min        start_time_10min  \n",
       "0                 600 2021-03-12 06:49:59.002  \n",
       "1                 600 2021-03-12 07:49:59.000  \n",
       "\n",
       "[2 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f138245-7922-4f89-9e70-9f8776e34509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
